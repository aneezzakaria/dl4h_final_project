{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "##import glove\n",
    "##from glove import Corpus\n",
    "\n",
    "import collections\n",
    "import gc \n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, merge, Activation, Concatenate, LSTM, GRU\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n",
    "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D, merge\n",
    "\n",
    "##from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "from keras.backend import set_session, clear_session, get_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dict_of_ner):\n",
    "    temp_data = []\n",
    "    for k, v in sorted(dict_of_ner.items()):\n",
    "        temp = []\n",
    "        for embed in v:\n",
    "            temp.append(embed)\n",
    "        temp_data.append(np.mean(temp, axis = 0)) \n",
    "    return np.asarray(temp_data)\n",
    "\n",
    "def make_prediction_multi_avg(model, test_data):\n",
    "    probs = model.predict(test_data)\n",
    "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
    "    return probs, y_pred\n",
    "\n",
    "def save_scores_multi_avg(predictions, probs, ground_truth, \n",
    "                          \n",
    "                          embed_name, problem_type, iteration, hidden_unit_size,\n",
    "                          \n",
    "                          sequence_name, type_of_ner):\n",
    "    \n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    result_dict = {}    \n",
    "    result_dict['auc'] = auc\n",
    "    result_dict['auprc'] = auprc\n",
    "    result_dict['acc'] = acc\n",
    "    result_dict['F1'] = F1\n",
    "    \n",
    "    result_path = \"results/\"\n",
    "    file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n",
    "    file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-avg-.p\"\n",
    "    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
    "\n",
    "    print(auc, auprc, acc, F1)\n",
    "    \n",
    "def avg_ner_model(layer_name, number_of_unit, embedding_name):\n",
    "\n",
    "    if embedding_name == \"concat\":\n",
    "        input_dimension = 200\n",
    "    else:\n",
    "        input_dimension = 100\n",
    "\n",
    "    sequence_input = Input(shape=(24,104))\n",
    "\n",
    "    input_avg = Input(shape=(input_dimension, ), name = \"avg\")        \n",
    "#     x_1 = Dense(256, activation='relu')(input_avg)\n",
    "#     x_1 = Dropout(0.3)(x_1)\n",
    "    \n",
    "    if layer_name == \"GRU\":\n",
    "        x = GRU(number_of_unit)(sequence_input)\n",
    "    elif layer_name == \"LSTM\":\n",
    "        x = LSTM(number_of_unit)(sequence_input)\n",
    "\n",
    "    x = keras.layers.Concatenate()([x, input_avg])\n",
    "\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    logits_regularizer = tf.keras.regularizers.L2(0.01)\n",
    "    \n",
    "    preds = Dense(1, activation='sigmoid',use_bias=False,\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal(), \n",
    "                  kernel_regularizer=logits_regularizer)(x)\n",
    "    \n",
    "    \n",
    "    opt = Adam(lr=0.001, decay = 0.01)\n",
    "    model = Model(inputs=[sequence_input, input_avg], outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_ner = \"new\"\n",
    "\n",
    "x_train_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_train.pkl\")\n",
    "x_dev_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_dev.pkl\")\n",
    "x_test_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_test.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(\"data/\"+type_of_ner+\"_y_train.pkl\")\n",
    "y_dev = pd.read_pickle(\"data/\"+type_of_ner+\"_y_dev.pkl\")\n",
    "y_test = pd.read_pickle(\"data/\"+type_of_ner+\"_y_test.pkl\")\n",
    "\n",
    "ner_word2vec = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_word2vec_limited_dict.pkl\")\n",
    "ner_fasttext = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_fasttext_limited_dict.pkl\")\n",
    "ner_concat = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_combined_limited_dict.pkl\")\n",
    "\n",
    "train_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_train_ids.pkl\")\n",
    "dev_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_dev_ids.pkl\")\n",
    "test_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_test_ids.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:  GRU\n",
      "Hidden unit:  128\n",
      "Embedding:  word2vec\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:42:42.012250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:42.109254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:42.109734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:42.111084: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 16:42:42.114638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:42.115126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:42.115528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:44.999236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:44.999775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:45.000233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:42:45.001629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:42:49.427488: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/238 [============================>.] - ETA: 0s - loss: 0.2947 - acc: 0.9016\n",
      "Epoch 1: val_loss improved from inf to 0.24434, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 10s 7ms/step - loss: 0.2945 - acc: 0.9018 - val_loss: 0.2443 - val_acc: 0.9164\n",
      "Epoch 2/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.2540 - acc: 0.9106\n",
      "Epoch 2: val_loss improved from 0.24434 to 0.24256, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2530 - acc: 0.9112 - val_loss: 0.2426 - val_acc: 0.9150\n",
      "Epoch 3/100\n",
      "236/238 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9174\n",
      "Epoch 3: val_loss improved from 0.24256 to 0.24048, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2389 - acc: 0.9173 - val_loss: 0.2405 - val_acc: 0.9159\n",
      "Epoch 4/100\n",
      "233/238 [============================>.] - ETA: 0s - loss: 0.2326 - acc: 0.9182\n",
      "Epoch 4: val_loss improved from 0.24048 to 0.23965, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2317 - acc: 0.9186 - val_loss: 0.2396 - val_acc: 0.9154\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2272 - acc: 0.9206\n",
      "Epoch 5: val_loss improved from 0.23965 to 0.23963, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2272 - acc: 0.9206 - val_loss: 0.2396 - val_acc: 0.9154\n",
      "Epoch 6/100\n",
      "235/238 [============================>.] - ETA: 0s - loss: 0.2225 - acc: 0.9225\n",
      "Epoch 6: val_loss did not improve from 0.23963\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2226 - acc: 0.9225 - val_loss: 0.2401 - val_acc: 0.9168\n",
      "Epoch 7/100\n",
      "235/238 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9210\n",
      "Epoch 7: val_loss improved from 0.23963 to 0.23913, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2206 - acc: 0.9211 - val_loss: 0.2391 - val_acc: 0.9159\n",
      "Epoch 8/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.2174 - acc: 0.9226\n",
      "Epoch 8: val_loss improved from 0.23913 to 0.23870, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2171 - acc: 0.9222 - val_loss: 0.2387 - val_acc: 0.9154\n",
      "Epoch 9/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9234\n",
      "Epoch 9: val_loss did not improve from 0.23870\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2149 - acc: 0.9228 - val_loss: 0.2390 - val_acc: 0.9154\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.2135 - acc: 0.9235\n",
      "Epoch 10: val_loss did not improve from 0.23870\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2135 - acc: 0.9235 - val_loss: 0.2393 - val_acc: 0.9154\n",
      "Epoch 11/100\n",
      "230/238 [===========================>..] - ETA: 0s - loss: 0.2114 - acc: 0.9256\n",
      "Epoch 11: val_loss did not improve from 0.23870\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2119 - acc: 0.9250 - val_loss: 0.2392 - val_acc: 0.9159\n",
      "Epoch 12/100\n",
      "235/238 [============================>.] - ETA: 0s - loss: 0.2099 - acc: 0.9258\n",
      "Epoch 12: val_loss did not improve from 0.23870\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2101 - acc: 0.9258 - val_loss: 0.2390 - val_acc: 0.9164\n",
      "Epoch 13/100\n",
      "233/238 [============================>.] - ETA: 0s - loss: 0.2096 - acc: 0.9247\n",
      "Epoch 13: val_loss did not improve from 0.23870\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2094 - acc: 0.9246 - val_loss: 0.2387 - val_acc: 0.9168\n",
      "0.8836312670719888 0.5935607920711763 0.9178932842686293 0.47730600292825764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:43:11.070683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:11.071213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:11.071514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:11.071873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:11.072241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:11.072490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "235/238 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9364\n",
      "Epoch 1: val_loss improved from inf to 0.18198, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 3s 7ms/step - loss: 0.2158 - acc: 0.9363 - val_loss: 0.1820 - val_acc: 0.9409\n",
      "Epoch 2/100\n",
      "235/238 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9412\n",
      "Epoch 2: val_loss improved from 0.18198 to 0.17752, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1840 - acc: 0.9414 - val_loss: 0.1775 - val_acc: 0.9427\n",
      "Epoch 3/100\n",
      "228/238 [===========================>..] - ETA: 0s - loss: 0.1748 - acc: 0.9440\n",
      "Epoch 3: val_loss improved from 0.17752 to 0.17733, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1736 - acc: 0.9446 - val_loss: 0.1773 - val_acc: 0.9427\n",
      "Epoch 4/100\n",
      "235/238 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9455\n",
      "Epoch 4: val_loss improved from 0.17733 to 0.17452, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1677 - acc: 0.9457 - val_loss: 0.1745 - val_acc: 0.9409\n",
      "Epoch 5/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.1632 - acc: 0.9471\n",
      "Epoch 5: val_loss improved from 0.17452 to 0.17384, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1635 - acc: 0.9470 - val_loss: 0.1738 - val_acc: 0.9422\n",
      "Epoch 6/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9470\n",
      "Epoch 6: val_loss improved from 0.17384 to 0.17285, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1601 - acc: 0.9472 - val_loss: 0.1729 - val_acc: 0.9427\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1591 - acc: 0.9475\n",
      "Epoch 7: val_loss improved from 0.17285 to 0.17249, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1591 - acc: 0.9475 - val_loss: 0.1725 - val_acc: 0.9409\n",
      "Epoch 8/100\n",
      "237/238 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9488\n",
      "Epoch 8: val_loss did not improve from 0.17249\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1550 - acc: 0.9489 - val_loss: 0.1729 - val_acc: 0.9399\n",
      "Epoch 9/100\n",
      "230/238 [===========================>..] - ETA: 0s - loss: 0.1529 - acc: 0.9497\n",
      "Epoch 9: val_loss improved from 0.17249 to 0.17227, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1534 - acc: 0.9497 - val_loss: 0.1723 - val_acc: 0.9399\n",
      "Epoch 10/100\n",
      "230/238 [===========================>..] - ETA: 0s - loss: 0.1512 - acc: 0.9497\n",
      "Epoch 10: val_loss did not improve from 0.17227\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1512 - acc: 0.9495 - val_loss: 0.1731 - val_acc: 0.9409\n",
      "Epoch 11/100\n",
      "234/238 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9501\n",
      "Epoch 11: val_loss did not improve from 0.17227\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1507 - acc: 0.9501 - val_loss: 0.1727 - val_acc: 0.9409\n",
      "Epoch 12/100\n",
      "234/238 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9500\n",
      "Epoch 12: val_loss did not improve from 0.17227\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1493 - acc: 0.9501 - val_loss: 0.1729 - val_acc: 0.9409\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 0.1469 - acc: 0.9505\n",
      "Epoch 13: val_loss did not improve from 0.17227\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1469 - acc: 0.9505 - val_loss: 0.1725 - val_acc: 0.9409\n",
      "Epoch 14/100\n",
      "233/238 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9523\n",
      "Epoch 14: val_loss did not improve from 0.17227\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1459 - acc: 0.9518 - val_loss: 0.1727 - val_acc: 0.9413\n",
      "0.8880003745493703 0.5252128168034454 0.9418123275068997 0.4535637149028078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:43:31.483438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:31.484055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:31.484445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:31.484843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:31.485164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:43:31.485420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type:  los_3\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.6940 - acc: 0.6129\n",
      "Epoch 1: val_loss improved from inf to 0.63186, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 3s 7ms/step - loss: 0.6927 - acc: 0.6138 - val_loss: 0.6319 - val_acc: 0.6677\n",
      "Epoch 2/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6409 - acc: 0.6536\n",
      "Epoch 2: val_loss improved from 0.63186 to 0.62992, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6418 - acc: 0.6527 - val_loss: 0.6299 - val_acc: 0.6650\n",
      "Epoch 3/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6283 - acc: 0.6732\n",
      "Epoch 3: val_loss improved from 0.62992 to 0.62483, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6286 - acc: 0.6724 - val_loss: 0.6248 - val_acc: 0.6728\n",
      "Epoch 4/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6197 - acc: 0.6791\n",
      "Epoch 4: val_loss improved from 0.62483 to 0.62091, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6198 - acc: 0.6788 - val_loss: 0.6209 - val_acc: 0.6742\n",
      "Epoch 5/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6154 - acc: 0.6752\n",
      "Epoch 5: val_loss did not improve from 0.62091\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6156 - acc: 0.6749 - val_loss: 0.6214 - val_acc: 0.6811\n",
      "Epoch 6/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6098 - acc: 0.6853\n",
      "Epoch 6: val_loss improved from 0.62091 to 0.61875, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6103 - acc: 0.6848 - val_loss: 0.6187 - val_acc: 0.6770\n",
      "Epoch 7/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6060 - acc: 0.6859\n",
      "Epoch 7: val_loss improved from 0.61875 to 0.61817, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6064 - acc: 0.6851 - val_loss: 0.6182 - val_acc: 0.6747\n",
      "Epoch 8/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.6044 - acc: 0.6932\n",
      "Epoch 8: val_loss did not improve from 0.61817\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6049 - acc: 0.6922 - val_loss: 0.6199 - val_acc: 0.6811\n",
      "Epoch 9/100\n",
      "230/238 [===========================>..] - ETA: 0s - loss: 0.6014 - acc: 0.6927\n",
      "Epoch 9: val_loss improved from 0.61817 to 0.61743, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6006 - acc: 0.6939 - val_loss: 0.6174 - val_acc: 0.6802\n",
      "Epoch 10/100\n",
      "236/238 [============================>.] - ETA: 0s - loss: 0.5998 - acc: 0.6956\n",
      "Epoch 10: val_loss did not improve from 0.61743\n",
      "238/238 [==============================] - 2s 6ms/step - loss: 0.5996 - acc: 0.6956 - val_loss: 0.6175 - val_acc: 0.6825\n",
      "Epoch 11/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5968 - acc: 0.6974\n",
      "Epoch 11: val_loss improved from 0.61743 to 0.61693, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5977 - acc: 0.6969 - val_loss: 0.6169 - val_acc: 0.6816\n",
      "Epoch 12/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.5971 - acc: 0.6962\n",
      "Epoch 12: val_loss improved from 0.61693 to 0.61631, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5964 - acc: 0.6966 - val_loss: 0.6163 - val_acc: 0.6798\n",
      "Epoch 13/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.5956 - acc: 0.6959\n",
      "Epoch 13: val_loss did not improve from 0.61631\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5943 - acc: 0.6967 - val_loss: 0.6176 - val_acc: 0.6862\n",
      "Epoch 14/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5918 - acc: 0.7025\n",
      "Epoch 14: val_loss did not improve from 0.61631\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5921 - acc: 0.7023 - val_loss: 0.6168 - val_acc: 0.6853\n",
      "Epoch 15/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5928 - acc: 0.7022\n",
      "Epoch 15: val_loss improved from 0.61631 to 0.61555, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5930 - acc: 0.7021 - val_loss: 0.6155 - val_acc: 0.6835\n",
      "Epoch 16/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5900 - acc: 0.7027\n",
      "Epoch 16: val_loss did not improve from 0.61555\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5894 - acc: 0.7031 - val_loss: 0.6156 - val_acc: 0.6821\n",
      "Epoch 17/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5883 - acc: 0.7041\n",
      "Epoch 17: val_loss did not improve from 0.61555\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5885 - acc: 0.7035 - val_loss: 0.6156 - val_acc: 0.6830\n",
      "Epoch 18/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.7065\n",
      "Epoch 18: val_loss improved from 0.61555 to 0.61547, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5868 - acc: 0.7063 - val_loss: 0.6155 - val_acc: 0.6798\n",
      "Epoch 19/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5865 - acc: 0.7074\n",
      "Epoch 19: val_loss did not improve from 0.61547\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5863 - acc: 0.7073 - val_loss: 0.6162 - val_acc: 0.6807\n",
      "Epoch 20/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.7039\n",
      "Epoch 20: val_loss did not improve from 0.61547\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5864 - acc: 0.7046 - val_loss: 0.6165 - val_acc: 0.6816\n",
      "Epoch 21/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.5841 - acc: 0.7082\n",
      "Epoch 21: val_loss did not improve from 0.61547\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5840 - acc: 0.7080 - val_loss: 0.6160 - val_acc: 0.6830\n",
      "Epoch 22/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.5845 - acc: 0.7046\n",
      "Epoch 22: val_loss improved from 0.61547 to 0.61533, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5844 - acc: 0.7045 - val_loss: 0.6153 - val_acc: 0.6793\n",
      "Epoch 23/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5825 - acc: 0.7105\n",
      "Epoch 23: val_loss improved from 0.61533 to 0.61519, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5834 - acc: 0.7103 - val_loss: 0.6152 - val_acc: 0.6807\n",
      "Epoch 24/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5811 - acc: 0.7095\n",
      "Epoch 24: val_loss did not improve from 0.61519\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5812 - acc: 0.7094 - val_loss: 0.6154 - val_acc: 0.6793\n",
      "Epoch 25/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5805 - acc: 0.7104\n",
      "Epoch 25: val_loss did not improve from 0.61519\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5803 - acc: 0.7104 - val_loss: 0.6163 - val_acc: 0.6793\n",
      "Epoch 26/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5795 - acc: 0.7098\n",
      "Epoch 26: val_loss did not improve from 0.61519\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5797 - acc: 0.7090 - val_loss: 0.6154 - val_acc: 0.6770\n",
      "Epoch 27/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5809 - acc: 0.7111\n",
      "Epoch 27: val_loss did not improve from 0.61519\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5806 - acc: 0.7117 - val_loss: 0.6161 - val_acc: 0.6816\n",
      "Epoch 28/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5802 - acc: 0.7116\n",
      "Epoch 28: val_loss did not improve from 0.61519\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5798 - acc: 0.7115 - val_loss: 0.6156 - val_acc: 0.6784\n",
      "0.7081046902582296 0.6457483447196932 0.6683532658693653 0.56877990430622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:44:10.234984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:10.235512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:10.235854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:10.236239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:10.236568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:10.236857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type:  los_7\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.9181\n",
      "Epoch 1: val_loss improved from inf to 0.26573, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 3s 7ms/step - loss: 0.2874 - acc: 0.9183 - val_loss: 0.2657 - val_acc: 0.9238\n",
      "Epoch 2/100\n",
      "236/238 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9215\n",
      "Epoch 2: val_loss improved from 0.26573 to 0.26474, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 2s 6ms/step - loss: 0.2599 - acc: 0.9214 - val_loss: 0.2647 - val_acc: 0.9205\n",
      "Epoch 3/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.2520 - acc: 0.9229\n",
      "Epoch 3: val_loss improved from 0.26474 to 0.26325, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2526 - acc: 0.9227 - val_loss: 0.2633 - val_acc: 0.9233\n",
      "Epoch 4/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2485 - acc: 0.9223\n",
      "Epoch 4: val_loss did not improve from 0.26325\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2486 - acc: 0.9223 - val_loss: 0.2634 - val_acc: 0.9242\n",
      "Epoch 5/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2449 - acc: 0.9214\n",
      "Epoch 5: val_loss improved from 0.26325 to 0.26132, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2446 - acc: 0.9216 - val_loss: 0.2613 - val_acc: 0.9233\n",
      "Epoch 6/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9225\n",
      "Epoch 6: val_loss did not improve from 0.26132\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2416 - acc: 0.9224 - val_loss: 0.2620 - val_acc: 0.9238\n",
      "Epoch 7/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9225\n",
      "Epoch 7: val_loss did not improve from 0.26132\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2421 - acc: 0.9224 - val_loss: 0.2615 - val_acc: 0.9242\n",
      "Epoch 8/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9229\n",
      "Epoch 8: val_loss improved from 0.26132 to 0.26054, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2377 - acc: 0.9229 - val_loss: 0.2605 - val_acc: 0.9238\n",
      "Epoch 9/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2389 - acc: 0.9224\n",
      "Epoch 9: val_loss did not improve from 0.26054\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2385 - acc: 0.9226 - val_loss: 0.2615 - val_acc: 0.9247\n",
      "Epoch 10/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9224\n",
      "Epoch 10: val_loss did not improve from 0.26054\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2341 - acc: 0.9225 - val_loss: 0.2606 - val_acc: 0.9238\n",
      "Epoch 11/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9226\n",
      "Epoch 11: val_loss improved from 0.26054 to 0.26047, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2352 - acc: 0.9224 - val_loss: 0.2605 - val_acc: 0.9238\n",
      "Epoch 12/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.2327 - acc: 0.9238\n",
      "Epoch 12: val_loss did not improve from 0.26047\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2334 - acc: 0.9234 - val_loss: 0.2612 - val_acc: 0.9238\n",
      "Epoch 13/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2334 - acc: 0.9225\n",
      "Epoch 13: val_loss did not improve from 0.26047\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2327 - acc: 0.9229 - val_loss: 0.2606 - val_acc: 0.9238\n",
      "Epoch 14/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2312 - acc: 0.9229\n",
      "Epoch 14: val_loss did not improve from 0.26047\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2313 - acc: 0.9230 - val_loss: 0.2605 - val_acc: 0.9238\n",
      "Epoch 15/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9233\n",
      "Epoch 15: val_loss did not improve from 0.26047\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2308 - acc: 0.9231 - val_loss: 0.2606 - val_acc: 0.9238\n",
      "Epoch 16/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2301 - acc: 0.9234\n",
      "Epoch 16: val_loss did not improve from 0.26047\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2302 - acc: 0.9233 - val_loss: 0.2608 - val_acc: 0.9238\n",
      "0.7345547837247529 0.22189273372811044 0.9181232750689973 0.021978021978021976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:44:34.212814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:34.213322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:34.213683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:34.214060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:34.214376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:34.214620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding:  fasttext\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/238 [===========================>..] - ETA: 0s - loss: 0.2920 - acc: 0.9014\n",
      "Epoch 1: val_loss improved from inf to 0.24191, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 3s 7ms/step - loss: 0.2914 - acc: 0.9018 - val_loss: 0.2419 - val_acc: 0.9164\n",
      "Epoch 2/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2498 - acc: 0.9148\n",
      "Epoch 2: val_loss improved from 0.24191 to 0.23832, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2500 - acc: 0.9148 - val_loss: 0.2383 - val_acc: 0.9164\n",
      "Epoch 3/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9175\n",
      "Epoch 3: val_loss improved from 0.23832 to 0.23612, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2374 - acc: 0.9176 - val_loss: 0.2361 - val_acc: 0.9159\n",
      "Epoch 4/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9197\n",
      "Epoch 4: val_loss improved from 0.23612 to 0.23469, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2291 - acc: 0.9200 - val_loss: 0.2347 - val_acc: 0.9159\n",
      "Epoch 5/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2261 - acc: 0.9209\n",
      "Epoch 5: val_loss improved from 0.23469 to 0.23415, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2255 - acc: 0.9213 - val_loss: 0.2341 - val_acc: 0.9145\n",
      "Epoch 6/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2230 - acc: 0.9219\n",
      "Epoch 6: val_loss improved from 0.23415 to 0.23334, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2222 - acc: 0.9225 - val_loss: 0.2333 - val_acc: 0.9154\n",
      "Epoch 7/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9228\n",
      "Epoch 7: val_loss improved from 0.23334 to 0.23198, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2183 - acc: 0.9234 - val_loss: 0.2320 - val_acc: 0.9136\n",
      "Epoch 8/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9227\n",
      "Epoch 8: val_loss did not improve from 0.23198\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2150 - acc: 0.9228 - val_loss: 0.2327 - val_acc: 0.9164\n",
      "Epoch 9/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.2139 - acc: 0.9229\n",
      "Epoch 9: val_loss improved from 0.23198 to 0.23120, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2138 - acc: 0.9231 - val_loss: 0.2312 - val_acc: 0.9140\n",
      "Epoch 10/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9238\n",
      "Epoch 10: val_loss did not improve from 0.23120\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2111 - acc: 0.9245 - val_loss: 0.2313 - val_acc: 0.9159\n",
      "Epoch 11/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9271\n",
      "Epoch 11: val_loss improved from 0.23120 to 0.23116, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2092 - acc: 0.9266 - val_loss: 0.2312 - val_acc: 0.9145\n",
      "Epoch 12/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9250\n",
      "Epoch 12: val_loss did not improve from 0.23116\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2092 - acc: 0.9255 - val_loss: 0.2317 - val_acc: 0.9154\n",
      "Epoch 13/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9242\n",
      "Epoch 13: val_loss did not improve from 0.23116\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2084 - acc: 0.9246 - val_loss: 0.2321 - val_acc: 0.9154\n",
      "Epoch 14/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9261\n",
      "Epoch 14: val_loss did not improve from 0.23116\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2062 - acc: 0.9267 - val_loss: 0.2317 - val_acc: 0.9136\n",
      "Epoch 15/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9265\n",
      "Epoch 15: val_loss did not improve from 0.23116\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2067 - acc: 0.9265 - val_loss: 0.2314 - val_acc: 0.9140\n",
      "Epoch 16/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2049 - acc: 0.9281\n",
      "Epoch 16: val_loss did not improve from 0.23116\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2043 - acc: 0.9282 - val_loss: 0.2313 - val_acc: 0.9140\n",
      "0.8814672548242136 0.581439448542092 0.9172033118675254 0.47058823529411775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:44:59.259075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:59.259591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:59.259933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:59.260447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:59.260795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:44:59.261038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type:  mort_icu\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.2191 - acc: 0.9333\n",
      "Epoch 1: val_loss improved from inf to 0.17830, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 3s 7ms/step - loss: 0.2201 - acc: 0.9329 - val_loss: 0.1783 - val_acc: 0.9432\n",
      "Epoch 2/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9410\n",
      "Epoch 2: val_loss improved from 0.17830 to 0.17445, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1831 - acc: 0.9413 - val_loss: 0.1744 - val_acc: 0.9427\n",
      "Epoch 3/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9441\n",
      "Epoch 3: val_loss improved from 0.17445 to 0.17257, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1750 - acc: 0.9439 - val_loss: 0.1726 - val_acc: 0.9413\n",
      "Epoch 4/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9444\n",
      "Epoch 4: val_loss improved from 0.17257 to 0.17166, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1698 - acc: 0.9447 - val_loss: 0.1717 - val_acc: 0.9427\n",
      "Epoch 5/100\n",
      "228/238 [===========================>..] - ETA: 0s - loss: 0.1675 - acc: 0.9455\n",
      "Epoch 5: val_loss improved from 0.17166 to 0.17015, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1661 - acc: 0.9461 - val_loss: 0.1702 - val_acc: 0.9390\n",
      "Epoch 6/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1621 - acc: 0.9474\n",
      "Epoch 6: val_loss improved from 0.17015 to 0.16988, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1619 - acc: 0.9472 - val_loss: 0.1699 - val_acc: 0.9409\n",
      "Epoch 7/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9477\n",
      "Epoch 7: val_loss improved from 0.16988 to 0.16972, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1589 - acc: 0.9480 - val_loss: 0.1697 - val_acc: 0.9404\n",
      "Epoch 8/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9480\n",
      "Epoch 8: val_loss improved from 0.16972 to 0.16913, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1577 - acc: 0.9480 - val_loss: 0.1691 - val_acc: 0.9399\n",
      "Epoch 9/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9489\n",
      "Epoch 9: val_loss improved from 0.16913 to 0.16880, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1551 - acc: 0.9486 - val_loss: 0.1688 - val_acc: 0.9390\n",
      "Epoch 10/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9497\n",
      "Epoch 10: val_loss improved from 0.16880 to 0.16879, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1541 - acc: 0.9493 - val_loss: 0.1688 - val_acc: 0.9413\n",
      "Epoch 11/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9507\n",
      "Epoch 11: val_loss improved from 0.16879 to 0.16853, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1516 - acc: 0.9506 - val_loss: 0.1685 - val_acc: 0.9409\n",
      "Epoch 12/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9508\n",
      "Epoch 12: val_loss did not improve from 0.16853\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1505 - acc: 0.9509 - val_loss: 0.1687 - val_acc: 0.9413\n",
      "Epoch 13/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9514\n",
      "Epoch 13: val_loss improved from 0.16853 to 0.16817, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1497 - acc: 0.9505 - val_loss: 0.1682 - val_acc: 0.9409\n",
      "Epoch 14/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9507\n",
      "Epoch 14: val_loss did not improve from 0.16817\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1485 - acc: 0.9509 - val_loss: 0.1684 - val_acc: 0.9404\n",
      "Epoch 15/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9514\n",
      "Epoch 15: val_loss did not improve from 0.16817\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1483 - acc: 0.9510 - val_loss: 0.1684 - val_acc: 0.9404\n",
      "Epoch 16/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9505\n",
      "Epoch 16: val_loss did not improve from 0.16817\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1465 - acc: 0.9507 - val_loss: 0.1682 - val_acc: 0.9413\n",
      "Epoch 17/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9517\n",
      "Epoch 17: val_loss did not improve from 0.16817\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1463 - acc: 0.9515 - val_loss: 0.1684 - val_acc: 0.9409\n",
      "Epoch 18/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9509\n",
      "Epoch 18: val_loss did not improve from 0.16817\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.1448 - acc: 0.9511 - val_loss: 0.1683 - val_acc: 0.9409\n",
      "0.8909530720851475 0.5234185302519323 0.9420423183072677 0.4349775784753363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:45:25.980516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:25.981038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:25.981355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:25.981717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:25.982035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:25.982300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type:  los_3\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.6851 - acc: 0.6207\n",
      "Epoch 1: val_loss improved from inf to 0.63510, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 3s 7ms/step - loss: 0.6847 - acc: 0.6198 - val_loss: 0.6351 - val_acc: 0.6608\n",
      "Epoch 2/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6393 - acc: 0.6571\n",
      "Epoch 2: val_loss improved from 0.63510 to 0.62606, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6389 - acc: 0.6577 - val_loss: 0.6261 - val_acc: 0.6682\n",
      "Epoch 3/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.6252 - acc: 0.6720\n",
      "Epoch 3: val_loss improved from 0.62606 to 0.62413, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6255 - acc: 0.6714 - val_loss: 0.6241 - val_acc: 0.6640\n",
      "Epoch 4/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6227 - acc: 0.6703\n",
      "Epoch 4: val_loss improved from 0.62413 to 0.62371, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6225 - acc: 0.6703 - val_loss: 0.6237 - val_acc: 0.6724\n",
      "Epoch 5/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6146 - acc: 0.6812\n",
      "Epoch 5: val_loss improved from 0.62371 to 0.62280, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6147 - acc: 0.6812 - val_loss: 0.6228 - val_acc: 0.6733\n",
      "Epoch 6/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6101 - acc: 0.6814\n",
      "Epoch 6: val_loss improved from 0.62280 to 0.61891, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6103 - acc: 0.6815 - val_loss: 0.6189 - val_acc: 0.6751\n",
      "Epoch 7/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6080 - acc: 0.6877\n",
      "Epoch 7: val_loss improved from 0.61891 to 0.61817, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6072 - acc: 0.6886 - val_loss: 0.6182 - val_acc: 0.6733\n",
      "Epoch 8/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6052 - acc: 0.6872\n",
      "Epoch 8: val_loss did not improve from 0.61817\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6042 - acc: 0.6879 - val_loss: 0.6189 - val_acc: 0.6765\n",
      "Epoch 9/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.6887\n",
      "Epoch 9: val_loss improved from 0.61817 to 0.61761, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6024 - acc: 0.6890 - val_loss: 0.6176 - val_acc: 0.6761\n",
      "Epoch 10/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.6913\n",
      "Epoch 10: val_loss did not improve from 0.61761\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6013 - acc: 0.6905 - val_loss: 0.6180 - val_acc: 0.6802\n",
      "Epoch 11/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5984 - acc: 0.6946\n",
      "Epoch 11: val_loss improved from 0.61761 to 0.61705, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5984 - acc: 0.6945 - val_loss: 0.6171 - val_acc: 0.6816\n",
      "Epoch 12/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5950 - acc: 0.6948\n",
      "Epoch 12: val_loss improved from 0.61705 to 0.61705, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5962 - acc: 0.6939 - val_loss: 0.6171 - val_acc: 0.6807\n",
      "Epoch 13/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.5956 - acc: 0.6955\n",
      "Epoch 13: val_loss did not improve from 0.61705\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5952 - acc: 0.6958 - val_loss: 0.6179 - val_acc: 0.6830\n",
      "Epoch 14/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5936 - acc: 0.6972\n",
      "Epoch 14: val_loss did not improve from 0.61705\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5939 - acc: 0.6970 - val_loss: 0.6175 - val_acc: 0.6835\n",
      "Epoch 15/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.5940 - acc: 0.6952\n",
      "Epoch 15: val_loss improved from 0.61705 to 0.61651, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5940 - acc: 0.6954 - val_loss: 0.6165 - val_acc: 0.6802\n",
      "Epoch 16/100\n",
      "230/238 [===========================>..] - ETA: 0s - loss: 0.5920 - acc: 0.6995\n",
      "Epoch 16: val_loss did not improve from 0.61651\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5910 - acc: 0.7006 - val_loss: 0.6165 - val_acc: 0.6779\n",
      "Epoch 17/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.5907 - acc: 0.6981\n",
      "Epoch 17: val_loss did not improve from 0.61651\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5900 - acc: 0.6991 - val_loss: 0.6177 - val_acc: 0.6853\n",
      "Epoch 18/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.5895 - acc: 0.7006\n",
      "Epoch 18: val_loss did not improve from 0.61651\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5901 - acc: 0.7000 - val_loss: 0.6170 - val_acc: 0.6788\n",
      "Epoch 19/100\n",
      "230/238 [===========================>..] - ETA: 0s - loss: 0.5880 - acc: 0.7018\n",
      "Epoch 19: val_loss did not improve from 0.61651\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5886 - acc: 0.7021 - val_loss: 0.6174 - val_acc: 0.6853\n",
      "Epoch 20/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.5878 - acc: 0.7012\n",
      "Epoch 20: val_loss did not improve from 0.61651\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.5871 - acc: 0.7020 - val_loss: 0.6183 - val_acc: 0.6853\n",
      "0.7047655734096412 0.6452979896629092 0.672263109475621 0.5755138516532619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:45:55.287323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:55.287875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:55.288280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:55.288693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:55.289032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:45:55.289287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type:  los_7\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "230/238 [===========================>..] - ETA: 0s - loss: 0.3083 - acc: 0.9132\n",
      "Epoch 1: val_loss improved from inf to 0.26957, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 3s 7ms/step - loss: 0.3072 - acc: 0.9135 - val_loss: 0.2696 - val_acc: 0.9224\n",
      "Epoch 2/100\n",
      "231/238 [============================>.] - ETA: 0s - loss: 0.2665 - acc: 0.9197\n",
      "Epoch 2: val_loss did not improve from 0.26957\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2659 - acc: 0.9199 - val_loss: 0.2712 - val_acc: 0.9238\n",
      "Epoch 3/100\n",
      "228/238 [===========================>..] - ETA: 0s - loss: 0.2551 - acc: 0.9217\n",
      "Epoch 3: val_loss improved from 0.26957 to 0.26779, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2567 - acc: 0.9213 - val_loss: 0.2678 - val_acc: 0.9238\n",
      "Epoch 4/100\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.2510 - acc: 0.9221\n",
      "Epoch 4: val_loss improved from 0.26779 to 0.26738, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 0.2523 - acc: 0.9219 - val_loss: 0.2674 - val_acc: 0.9242\n",
      "Epoch 5/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2503 - acc: 0.9216\n",
      "Epoch 5: val_loss did not improve from 0.26738\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.9219 - val_loss: 0.2677 - val_acc: 0.9242\n",
      "Epoch 6/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.9218\n",
      "Epoch 6: val_loss improved from 0.26738 to 0.26639, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2472 - acc: 0.9219 - val_loss: 0.2664 - val_acc: 0.9247\n",
      "Epoch 7/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2446 - acc: 0.9221\n",
      "Epoch 7: val_loss improved from 0.26639 to 0.26508, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2437 - acc: 0.9226 - val_loss: 0.2651 - val_acc: 0.9247\n",
      "Epoch 8/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9230\n",
      "Epoch 8: val_loss improved from 0.26508 to 0.26504, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2429 - acc: 0.9227 - val_loss: 0.2650 - val_acc: 0.9247\n",
      "Epoch 9/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9219\n",
      "Epoch 9: val_loss did not improve from 0.26504\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2403 - acc: 0.9223 - val_loss: 0.2651 - val_acc: 0.9247\n",
      "Epoch 10/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9225\n",
      "Epoch 10: val_loss did not improve from 0.26504\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2380 - acc: 0.9229 - val_loss: 0.2656 - val_acc: 0.9247\n",
      "Epoch 11/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2373 - acc: 0.9230\n",
      "Epoch 11: val_loss did not improve from 0.26504\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2378 - acc: 0.9227 - val_loss: 0.2657 - val_acc: 0.9247\n",
      "Epoch 12/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2375 - acc: 0.9235\n",
      "Epoch 12: val_loss did not improve from 0.26504\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2382 - acc: 0.9229 - val_loss: 0.2654 - val_acc: 0.9247\n",
      "Epoch 13/100\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.2351 - acc: 0.9232\n",
      "Epoch 13: val_loss did not improve from 0.26504\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.2358 - acc: 0.9231 - val_loss: 0.2653 - val_acc: 0.9242\n",
      "0.7307860102226926 0.21809373682450478 0.9188132474701012 0.03287671232876712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:46:15.632007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:46:15.632540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:46:15.632847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:46:15.633223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:46:15.633547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 16:46:15.633806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6902 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding:  concat\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 1 of layer \"model\" is incompatible with the layer: expected shape=(None, 200), found shape=(None, 100)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3242/2006996277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n\u001b[1;32m     51\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_dev_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dev_ner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach_problem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                               batch_size=batch_size )\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 1 of layer \"model\" is incompatible with the layer: expected shape=(None, 200), found shape=(None, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_types = ['word2vec', 'fasttext', 'concat']\n",
    "embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
    "target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
    "\n",
    "\n",
    "num_epoch = 100\n",
    "model_patience = 5\n",
    "monitor_criteria = 'val_loss'\n",
    "batch_size = 64\n",
    "iter_num = 2\n",
    "unit_sizes = [128, 256]\n",
    "\n",
    "#layers = [\"LSTM\", \"GRU\"]\n",
    "layers = [\"GRU\"]\n",
    "for each_layer in layers:\n",
    "    print (\"Layer: \", each_layer)\n",
    "    for each_unit_size in unit_sizes:\n",
    "        print (\"Hidden unit: \", each_unit_size)\n",
    "\n",
    "        for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n",
    "            print (\"Embedding: \", embed_name)\n",
    "            print(\"=============================\")\n",
    "\n",
    "            temp_train_ner = dict((k, ner_word2vec[k]) for k in train_ids)\n",
    "            temp_dev_ner = dict((k, ner_word2vec[k]) for k in dev_ids)\n",
    "            temp_test_ner = dict((k, ner_word2vec[k]) for k in test_ids)\n",
    "\n",
    "            x_train_ner = create_dataset(temp_train_ner)\n",
    "            x_dev_ner = create_dataset(temp_dev_ner)\n",
    "            x_test_ner = create_dataset(temp_test_ner)\n",
    "\n",
    "\n",
    "            for iteration in range(1, iter_num):\n",
    "                print (\"Iteration number: \", iteration)\n",
    "\n",
    "                for each_problem in target_problems:\n",
    "                    print (\"Problem type: \", each_problem)\n",
    "                    print (\"__________________\")\n",
    "\n",
    "                    early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "                    best_model_name = \"avg-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "                    checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1,\n",
    "                        save_best_only=True, mode='min', period=1)\n",
    "\n",
    "\n",
    "                    callbacks = [early_stopping_monitor, checkpoint]\n",
    "\n",
    "                    model = avg_ner_model(each_layer, each_unit_size, embed_name)\n",
    "                    \n",
    "                    model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n",
    "                              validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, \n",
    "                              batch_size=batch_size )\n",
    "\n",
    "                    model.load_weights(best_model_name)\n",
    "\n",
    "                    probs, predictions = make_prediction_multi_avg(model, [x_test_lstm, x_test_ner])\n",
    "                    \n",
    "                    save_scores_multi_avg(predictions, probs, y_test[each_problem], \n",
    "                                embed_name, each_problem, iteration, each_unit_size, \n",
    "                                each_layer, type_of_ner)\n",
    "                    \n",
    "                    #reset_keras(model)\n",
    "                    #del model\n",
    "                    sess = get_session()\n",
    "                    \n",
    "                    clear_session()\n",
    "                    sess.close()\n",
    "                    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
