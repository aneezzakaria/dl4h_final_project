{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "##import glove\n",
    "##from glove import Corpus\n",
    "\n",
    "import collections\n",
    "import gc \n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, merge, Activation, Concatenate, LSTM, GRU\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n",
    "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D, merge\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "from keras.backend import set_session, clear_session, get_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras(model):\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del model # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    gc.collect() # if it's done something you should see a number being outputted\n",
    "\n",
    "def make_prediction_timeseries(model, test_data):\n",
    "    probs = model.predict(test_data)\n",
    "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
    "    return probs, y_pred\n",
    "\n",
    "def save_scores_timeseries(predictions, probs, ground_truth, model_name, \n",
    "                problem_type, iteration, hidden_unit_size, type_of_ner):\n",
    "    \n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    \n",
    "    result_dict = {}    \n",
    "    result_dict['auc'] = auc\n",
    "    result_dict['auprc'] = auprc\n",
    "    result_dict['acc'] = acc\n",
    "    result_dict['F1'] = F1\n",
    "\n",
    "        \n",
    "    file_name = str(hidden_unit_size)+\"-\"+model_name+\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\".p\"\n",
    "    \n",
    "    result_path = \"results/\"\n",
    "    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
    "\n",
    "    print(auc, auprc, acc, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_model(layer_name, number_of_unit):\n",
    "    K.clear_session()\n",
    "    \n",
    "    sequence_input = Input(shape=(24,104),  name = \"timeseries_input\")\n",
    "    \n",
    "    if layer_name == \"LSTM\":\n",
    "        x = LSTM(number_of_unit)(sequence_input)\n",
    "    else:\n",
    "        x = GRU(number_of_unit)(sequence_input)\n",
    "    \n",
    "    logits_regularizer = tf.keras.regularizers.L2(0.01)\n",
    "    sigmoid_pred = Dense(1, activation='sigmoid',use_bias=False,\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal(), \n",
    "                  kernel_regularizer=logits_regularizer)(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=sequence_input, outputs=sigmoid_pred)\n",
    "    \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_ner = \"new\"\n",
    "\n",
    "x_train_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_train.pkl\")\n",
    "x_dev_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_dev.pkl\")\n",
    "x_test_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_test.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(\"data/\"+type_of_ner+\"_y_train.pkl\")\n",
    "y_dev = pd.read_pickle(\"data/\"+type_of_ner+\"_y_dev.pkl\")\n",
    "y_test = pd.read_pickle(\"data/\"+type_of_ner+\"_y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:  LSTM\n",
      "Hidden unit:  128\n",
      "Iteration number:  1\n",
      "=============================\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:21:01.753921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:01.764336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:01.764732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:01.765593: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 23:21:01.767100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:01.767449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:01.767747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:02.301653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:02.302119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:02.302447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 23:21:02.302708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 81 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n",
      "2022-05-06 23:21:02.312356: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 81.81M (85786624 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-06 23:21:12.806449: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 144.91MiB (rounded to 151946496)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-05-06 23:21:12.806499: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-05-06 23:21:12.806512: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 12, Chunks in use: 11. 3.0KiB allocated for chunks. 2.8KiB in use in bin. 52B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806520: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806527: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806534: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 1, Chunks in use: 1. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806550: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806557: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806563: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806570: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806576: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806584: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 208.0KiB allocated for chunks. 208.0KiB in use in bin. 208.0KiB client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806592: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 2, Chunks in use: 1. 667.2KiB allocated for chunks. 256.0KiB in use in bin. 256.0KiB client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806599: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 512.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806605: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806611: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806617: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806623: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806629: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806637: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806644: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0. 72.27MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806650: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806657: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-06 23:21:12.806664: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 144.91MiB was 128.00MiB, Chunk State: \n",
      "2022-05-06 23:21:12.806670: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 77208064\n",
      "2022-05-06 23:21:12.806679: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000000 of size 1280 next 1\n",
      "2022-05-06 23:21:12.806685: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000500 of size 256 next 2\n",
      "2022-05-06 23:21:12.806690: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000600 of size 256 next 3\n",
      "2022-05-06 23:21:12.806695: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000700 of size 256 next 4\n",
      "2022-05-06 23:21:12.806701: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000800 of size 256 next 5\n",
      "2022-05-06 23:21:12.806706: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000900 of size 256 next 10\n",
      "2022-05-06 23:21:12.806711: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000a00 of size 256 next 12\n",
      "2022-05-06 23:21:12.806716: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000b00 of size 256 next 11\n",
      "2022-05-06 23:21:12.806721: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000c00 of size 256 next 8\n",
      "2022-05-06 23:21:12.806726: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000d00 of size 256 next 16\n",
      "2022-05-06 23:21:12.806750: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000e00 of size 256 next 18\n",
      "2022-05-06 23:21:12.806755: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be000f00 of size 256 next 19\n",
      "2022-05-06 23:21:12.806760: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f22be001000 of size 256 next 17\n",
      "2022-05-06 23:21:12.806766: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be001100 of size 512 next 14\n",
      "2022-05-06 23:21:12.806772: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be001300 of size 2048 next 15\n",
      "2022-05-06 23:21:12.806777: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f22be001b00 of size 421120 next 6\n",
      "2022-05-06 23:21:12.806783: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be068800 of size 212992 next 7\n",
      "2022-05-06 23:21:12.806788: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f22be09c800 of size 524288 next 9\n",
      "2022-05-06 23:21:12.806817: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f22be11c800 of size 262144 next 13\n",
      "2022-05-06 23:21:12.806823: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f22be15c800 of size 75780608 next 18446744073709551615\n",
      "2022-05-06 23:21:12.806828: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-05-06 23:21:12.806834: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 11 Chunks of size 256 totalling 2.8KiB\n",
      "2022-05-06 23:21:12.806841: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 512 totalling 512B\n",
      "2022-05-06 23:21:12.806847: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-05-06 23:21:12.806852: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2048 totalling 2.0KiB\n",
      "2022-05-06 23:21:12.806858: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 212992 totalling 208.0KiB\n",
      "2022-05-06 23:21:12.806864: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 262144 totalling 256.0KiB\n",
      "2022-05-06 23:21:12.806870: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 470.5KiB\n",
      "2022-05-06 23:21:12.806876: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 77208064 memory_limit_: 85786624 available bytes: 8578560 curr_region_allocation_bytes_: 171573248\n",
      "2022-05-06 23:21:12.806886: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                        85786624\n",
      "InUse:                          481792\n",
      "MaxInUse:                      1231872\n",
      "NumAllocs:                          33\n",
      "MaxAllocSize:                   425728\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-05-06 23:21:12.806894: W tensorflow/core/common_runtime/bfc_allocator.cc:474] **__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3244/2632415402.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeseries_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_unit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 model.fit(x_train_lstm, y_train[each_problem], epochs=epoch_num, verbose=1, \n\u001b[0;32m---> 35\u001b[0;31m                           validation_data=(x_dev_lstm, y_dev[each_problem]), callbacks=callbacks, batch_size= batch_size)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "model_patience = 3\n",
    "monitor_criteria = 'val_loss'\n",
    "batch_size = 128\n",
    "\n",
    "unit_sizes = [128, 256]\n",
    "#unit_sizes = [256]\n",
    "iter_num = 11\n",
    "target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
    "layers = [\"LSTM\", \"GRU\"]\n",
    "#layers = [\"GRU\"]\n",
    "for each_layer in layers:\n",
    "    print(\"Layer: \", each_layer)\n",
    "    for each_unit_size in unit_sizes:\n",
    "        print(\"Hidden unit: \", each_unit_size)\n",
    "        for iteration in range(1, iter_num):\n",
    "            print(\"Iteration number: \", iteration)\n",
    "            print(\"=============================\")\n",
    "\n",
    "            for each_problem in target_problems:\n",
    "                print (\"Problem type: \", each_problem)\n",
    "                print (\"__________________\")\n",
    "\n",
    "\n",
    "                early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "                best_model_name = str(each_layer)+\"-\"+str(each_unit_size)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "                checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1,\n",
    "                    save_best_only=True, mode='min', period=1)\n",
    "\n",
    "\n",
    "                callbacks = [early_stopping_monitor, checkpoint]\n",
    "\n",
    "                model = timeseries_model(each_layer, each_unit_size)\n",
    "                model.fit(x_train_lstm, y_train[each_problem], epochs=epoch_num, verbose=1, \n",
    "                          validation_data=(x_dev_lstm, y_dev[each_problem]), callbacks=callbacks, batch_size= batch_size)\n",
    "\n",
    "                model.load_weights(best_model_name)\n",
    "\n",
    "                probs, predictions = make_prediction_timeseries(model, x_test_lstm)\n",
    "                save_scores_timeseries(predictions, probs, y_test[each_problem].values,str(each_layer),\n",
    "                                       each_problem, iteration, each_unit_size,type_of_ner)\n",
    "                reset_keras(model)\n",
    "                #del model\n",
    "                clear_session()\n",
    "                gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
