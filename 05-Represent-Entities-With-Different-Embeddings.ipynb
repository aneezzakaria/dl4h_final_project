{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "###import glove\n",
    "###from glove import Corpus\n",
    "\n",
    "import collections\n",
    "import gc \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp37-cp37m-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/aneezzakaria/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/aneezzakaria/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/aneezzakaria/opt/anaconda3/lib/python3.7/site-packages (from gensim) (5.2.1)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glove-py\n",
      "  Downloading glove_py-0.2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.2\n",
      "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/aneezzakaria/opt/anaconda3/lib/python3.7/site-packages (from glove-py) (62.1.0)\n",
      "Requirement already satisfied: numpy in /Users/aneezzakaria/opt/anaconda3/lib/python3.7/site-packages (from glove-py) (1.18.1)\n",
      "Building wheels for collected packages: glove-py\n",
      "  Building wheel for glove-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for glove-py: filename=glove_py-0.2.3-cp37-cp37m-macosx_10_9_x86_64.whl size=78657 sha256=655a0cc0bb130b0decd1d920672a7e1b0e6b21fdf8d84d8c8d92e37e142fc788\n",
      "  Stored in directory: /Users/aneezzakaria/Library/Caches/pip/wheels/f4/03/3d/bb3b646c1fadfecf585bcf02be3920ac8322e958bf2637cfcf\n",
      "Successfully built glove-py\n",
      "Installing collected packages: pybind11, glove-py\n",
      "Successfully installed glove-py-0.2.3 pybind11-2.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install glove-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_notes = pd.read_pickle(\"data/ner_df.p\") # med7\n",
    "w2vec = Word2Vec.load(\"embeddings/word2vec.model\")\n",
    "fasttext = FastText.load(\"embeddings/fasttext.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_index_list = []\n",
    "for i in new_notes.itertuples():\n",
    "    \n",
    "    if len(i.ner) == 0:\n",
    "        null_index_list.append(i.Index)\n",
    "new_notes.drop(null_index_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "med7_ner_data = {}\n",
    "\n",
    "for ii in new_notes.itertuples():\n",
    "    \n",
    "    p_id = ii.SUBJECT_ID\n",
    "    ind = ii.Index\n",
    "    \n",
    "    try:\n",
    "        new_ner = new_notes.loc[ind].ner\n",
    "    except:\n",
    "        new_ner = []\n",
    "            \n",
    "    unique = set()\n",
    "    new_temp = []\n",
    "    \n",
    "    for j in new_ner:\n",
    "        for k in j:\n",
    "            \n",
    "            unique.add(k[0])\n",
    "            new_temp.append(k)\n",
    "\n",
    "    if p_id in med7_ner_data:\n",
    "        for i in new_temp:\n",
    "            med7_ner_data[p_id].append(i)\n",
    "    else:\n",
    "        med7_ner_data[p_id] = new_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(med7_ner_data, \"data/new_ner_word_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2vec starting..\n",
      "fasttext starting..\n",
      "combined starting..\n",
      "21731 21657 21837\n"
     ]
    }
   ],
   "source": [
    "data_types = [med7_ner_data]\n",
    "data_names = [\"new_ner\"]\n",
    "\n",
    "for data, names in zip(data_types, data_names):\n",
    "    new_word2vec = {}\n",
    "    print(\"w2vec starting..\")\n",
    "    for k,v in data.items():\n",
    "\n",
    "        patient_temp = []\n",
    "        for i in v:\n",
    "            try:\n",
    "                patient_temp.append(w2vec.wv[i[0]])\n",
    "            except:\n",
    "                avg = []\n",
    "                num = 0\n",
    "                temp = []\n",
    "\n",
    "                if len(i[0].split(\" \")) > 1:\n",
    "                    for each_word in i[0].split(\" \"):\n",
    "                        try:\n",
    "                            temp = w2vec.wv[each_word]\n",
    "                            avg.append(temp)\n",
    "                            num += 1\n",
    "                        except:\n",
    "                            pass\n",
    "                    if num == 0: continue\n",
    "                    avg = np.asarray(avg)\n",
    "                    t = np.asarray(list(map(mean, zip(*avg))))\n",
    "                    patient_temp.append(t)\n",
    "        if len(patient_temp) == 0: continue\n",
    "        new_word2vec[k] = patient_temp\n",
    "\n",
    "    #############################################################################\n",
    "    print(\"fasttext starting..\")\n",
    "        \n",
    "    new_fasttextvec = {}\n",
    "\n",
    "    for k,v in data.items():\n",
    "\n",
    "        patient_temp = []\n",
    "\n",
    "        for i in v:\n",
    "            try:\n",
    "                patient_temp.append(fasttext.wv[i[0]])\n",
    "            except:\n",
    "                pass\n",
    "        if len(patient_temp) == 0: continue\n",
    "        new_fasttextvec[k] = patient_temp\n",
    "\n",
    "    #############################################################################    \n",
    "        \n",
    "    print(\"combined starting..\")\n",
    "    new_concatvec = {}\n",
    "\n",
    "    for k,v in data.items():\n",
    "        patient_temp = []\n",
    "        #if k != 6: continue\n",
    "        for i in v:\n",
    "            w2vec_temp = []\n",
    "            fasttemp = []\n",
    "            try:\n",
    "                w2vec_temp = w2vec.wv[i[0]]\n",
    "            except:\n",
    "                avg = []\n",
    "                num = 0\n",
    "                temp = []\n",
    "\n",
    "                if len(i[0].split(\" \")) > 1:\n",
    "                    for each_word in i[0].split(\" \"):\n",
    "                        try:\n",
    "                            temp = w2vec.wv[each_word]\n",
    "                            avg.append(temp)\n",
    "                            num += 1\n",
    "                        except:\n",
    "                            pass\n",
    "                    if num == 0: \n",
    "                        w2vec_temp = [0] * 100\n",
    "                    else:\n",
    "                        avg = np.asarray(avg)\n",
    "                        w2vec_temp = np.asarray(list(map(mean, zip(*avg))))\n",
    "                else:\n",
    "                    w2vec_temp = [0] * 100\n",
    "\n",
    "            try:\n",
    "                fasttemp = fasttext.wv[i[0]]\n",
    "            except:\n",
    "                fasttemp = [0] * 100\n",
    "            ##print(fasttemp)\n",
    "\n",
    "            appended = np.append(fasttemp, w2vec_temp, 0)\n",
    "            patient_temp.append(appended)\n",
    "        if len(patient_temp) == 0: continue\n",
    "        new_concatvec[k] = patient_temp\n",
    "\n",
    "    print(len(new_word2vec), len(new_fasttextvec), len(new_concatvec))\n",
    "    pd.to_pickle(new_word2vec, \"data/\"+names+\"_word2vec_dict.pkl\")\n",
    "    pd.to_pickle(new_fasttextvec, \"data/\"+names+\"_fasttext_dict.pkl\")\n",
    "    pd.to_pickle(new_concatvec, \"data/\"+names+\"_combined_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21731 21657 21837\n"
     ]
    }
   ],
   "source": [
    "diff = set(new_fasttextvec.keys()).difference(set(new_word2vec))\n",
    "for i in diff:\n",
    "    del new_fasttext[i]\n",
    "    del new_combined[i]\n",
    "print (len(new_word2vec), len(new_fasttextvec), len(new_concatvec))\n",
    "\n",
    "\n",
    "pd.to_pickle(new_word2vec, \"data/\"+\"new_ner\"+\"_word2vec_limited_dict.pkl\")\n",
    "pd.to_pickle(new_fasttextvec, \"data/\"+\"new_ner\"+\"_fasttext_limited_dict.pkl\")\n",
    "pd.to_pickle(new_concatvec, \"data/\"+\"new_ner\"+\"_combined_limited_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
